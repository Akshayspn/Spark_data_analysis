{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation "
      ],
      "metadata": {
        "id": "gI2x0JF2Cj2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3-Pa5tMtutr"
      },
      "outputs": [],
      "source": [
        "# data set downoad instructions from kaggle. We are using opensource temperature data available at Kaggle.\n",
        "#We will download data using kaggle API at run time. To understand how kaggle API works, please visit kaggle link \n",
        "# https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "FBkbEMkDyGF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "FgFjmVJKypsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload Kaggle JSON API credential file"
      ],
      "metadata": {
        "id": "TjAMV1LOCtP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "H5OQ706zytPe",
        "outputId": "6ee308cc-1a7f-4b9a-dccf-a9e0a0026dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a5f7fe3-c65f-4816-974b-f94037a9d48b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a5f7fe3-c65f-4816-974b-f94037a9d48b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"akshay0\",\"key\":\"6af1c14002ef22c1871e98ae67aacaa5\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create directory to save Json credential file, copy JSON file and change permissions \n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "lpqyY5V3yyni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424bd484-5407-49d5-d6e2-f2a3f4bb720d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download kaggle temperature dataset daily-temperature-of-major-cities\n",
        "! kaggle datasets download -d sudalairajkumar/daily-temperature-of-major-cities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scYJZT52zhRr",
        "outputId": "28aa7b5f-6907-4981-a827-eaef05eed377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "daily-temperature-of-major-cities.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip downloaded file\n",
        "! unzip daily-temperature-of-major-cities.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaXs8jijzkd-",
        "outputId": "27685ddb-3f63-4cea-fc8f-99ad7e4631e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  daily-temperature-of-major-cities.zip\n",
            "replace city_temperature.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "un-ucP48Do0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Enviornment- Install JDK 8, Pyspark version 3.2.1"
      ],
      "metadata": {
        "id": "zOzFJYJNDpmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==3.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqIYgdyI0TEZ",
        "outputId": "8cd6bc0a-2a62-445d-eff5-e5f0b4974047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_352\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_352-8u352-ga-1~20.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.2.1\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853643 sha256=a75a72b8bb7c4da25622afdb2a6fceb265935a722a473b32078aec8029570c4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/94/83/915c9059e4b038e2d43a6058f307fe1c3e8536e5745f3b23b7\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pyspark --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabL29yV1PeE",
        "outputId": "1fcfd159-dd74-4a79-d911-6608b9a5ff36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.2.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 1.8.0_352\n",
            "Branch HEAD\n",
            "Compiled by user hgao on 2022-01-20T19:26:14Z\n",
            "Revision 4f25b3f71238a00508a356591553f2dfa89f8290\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Pyspark and creating spark session"
      ],
      "metadata": {
        "id": "WP99SgAlEBOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set enviornment variable SPARK_VERSION\n",
        "! export SPARK_VERSION=3.2.1\n",
        "import pyspark\n",
        "import pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.config('spark.ui.port', '4050').getOrCreate()"
      ],
      "metadata": {
        "id": "qWUgchiA2Ayd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing data into spark"
      ],
      "metadata": {
        "id": "f_C_yChFETHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "data_path = '/content/city_temperature.csv'\n",
        "data = spark.read.csv(data_path, header=True)"
      ],
      "metadata": {
        "id": "Vp1wrjPy0-jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect Schema\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa7e9OnDJleo",
        "outputId": "3761ea4a-73e5-4ac1-beb7-d9d34ebd6785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Month: string (nullable = true)\n",
            " |-- Day: string (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            " |-- AvgTemperature: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y1XxYSS1mgo",
        "outputId": "3abbb661-04a4-46f2-ee81-0bf2499a7563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='1', Year='1995', AvgTemperature='64.2'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='2', Year='1995', AvgTemperature='49.4'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='3', Year='1995', AvgTemperature='48.8'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='4', Year='1995', AvgTemperature='46.4'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='5', Year='1995', AvgTemperature='47.9')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLfsRphgEtM4",
        "outputId": "a0526a6a-d3f7-49b3-c616-cbc2c136d0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-------+-----+---+----+--------------+\n",
            "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+\n",
            "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|\n",
            "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|\n",
            "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets explore and clean data using Python API functions"
      ],
      "metadata": {
        "id": "hF-3Ik66xhCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,FloatType\n",
        "data_df = data.withColumn(\"Avgtempcent\", data[\"AvgTemperature\"].cast(FloatType()))\n",
        "data_clean=data_df.where(\"Avgtempcent> -99\")"
      ],
      "metadata": {
        "id": "MwJ9ANT2C74J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRgszh1dEHv9",
        "outputId": "8b8db23f-56f2-4989-8b19-f5e4426a06f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+\n",
            "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|Avgtempcent|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+\n",
            "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|       64.2|\n",
            "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|       49.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|       48.8|\n",
            "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|       46.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|       47.9|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformations"
      ],
      "metadata": {
        "id": "FhuqwTZDF2qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# But Temperature given in Farenheight, Lets convert to Celcius scale"
      ],
      "metadata": {
        "id": "-e_yh_yIFdT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df1 = data_clean.withColumn(\"Avgtempcentconv\", 5/9*(data_df[\"Avgtempcent\"]-9))\n",
        "data_df1.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHxuSiCziTz8",
        "outputId": "63e80be3-41cf-4858-ccee-7eb40ab37ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+------------------+\n",
            "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|Avgtempcent|   Avgtempcentconv|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+------------------+\n",
            "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|       64.2|30.666664971245662|\n",
            "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|       49.4| 22.44444529215495|\n",
            "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|       48.8| 22.11111068725586|\n",
            "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|       46.4| 20.77777862548828|\n",
            "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|       47.9|21.611111958821617|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "aofJd3_rGXIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean temp of all countries of Asia region for each year\n",
        "data_df1.select('Region','Country','City','Year','Avgtempcentconv').where(\"Region=='Asia'\")\\\n",
        ".groupBy(\"Country\",\"Year\").agg(F.mean('Avgtempcentconv')).orderBy(\"Country\",\"Year\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG7NcAqS3wSu",
        "outputId": "d23112e0-5aea-4644-9a06-77dd0a032b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+--------------------+\n",
            "|   Country|Year|avg(Avgtempcentconv)|\n",
            "+----------+----+--------------------+\n",
            "|Bangladesh|1995|   39.08342950301002|\n",
            "|Bangladesh|1996|  38.758802764665724|\n",
            "|Bangladesh|1997|   37.86378861750306|\n",
            "|Bangladesh|1998|  39.048365898381654|\n",
            "|Bangladesh|1999|  37.826599336232384|\n",
            "+----------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean temp of all countries of Asia region for each year\n",
        "data_df1.select('Region','Country','City','Year','Avgtempcentconv').where(\"Region=='Asia'\")\\\n",
        ".groupBy(\"Country\",\"Year\").agg(F.mean('Avgtempcentconv')).orderBy(\"Country\",\"Year\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vceWOaC6HT12",
        "outputId": "ed2eeb4d-c47f-4a62-8f94-7347431971bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [Country#416 ASC NULLS FIRST, Year#421 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(Country#416 ASC NULLS FIRST, Year#421 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#590]\n",
            "      +- HashAggregate(keys=[Country#416, Year#421], functions=[avg(Avgtempcentconv#535)])\n",
            "         +- Exchange hashpartitioning(Country#416, Year#421, 200), ENSURE_REQUIREMENTS, [id=#587]\n",
            "            +- HashAggregate(keys=[Country#416, Year#421], functions=[partial_avg(Avgtempcentconv#535)])\n",
            "               +- Project [Country#416, Year#421, (cast((cast(AvgTemperature#422 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#535]\n",
            "                  +- Filter (((isnotnull(AvgTemperature#422) AND isnotnull(Region#415)) AND (cast(AvgTemperature#422 as float) > -99.0)) AND (Region#415 = Asia))\n",
            "                     +- FileScan csv [Region#415,Country#416,Year#421,AvgTemperature#422] Batched: false, DataFilters: [isnotnull(AvgTemperature#422), isnotnull(Region#415), (cast(AvgTemperature#422 as float) > -99.0..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature), IsNotNull(Region), EqualTo(Region,Asia)], ReadSchema: struct<Region:string,Country:string,Year:string,AvgTemperature:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SQL in Spark Jobs"
      ],
      "metadata": {
        "id": "2EXssmfKxV7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create& register a view on our dataframe\n",
        "data_df1.createOrReplaceTempView(\"Temperature\")"
      ],
      "metadata": {
        "id": "NQgxatoGGe_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets Run sql Query to fetch average temperature of countries for each year of Asia Region\n",
        "df=spark.sql(\"select Country,Year, AVG(Avgtempcentconv) from Temperature where region='Asia' group by 1,2 order by 1,2\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cR4zbuS5On-",
        "outputId": "73a1236b-07e4-4dc7-b745-6df24e110baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+--------------------+\n",
            "|   Country|Year|avg(Avgtempcentconv)|\n",
            "+----------+----+--------------------+\n",
            "|Bangladesh|1995|   39.08342950301002|\n",
            "|Bangladesh|1996|  38.758802764665724|\n",
            "|Bangladesh|1997|   37.86378861750306|\n",
            "|Bangladesh|1998|  39.048365898381654|\n",
            "|Bangladesh|1999|  37.826599336232384|\n",
            "+----------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, does we have same explain plan as before??"
      ],
      "metadata": {
        "id": "wLEyyDdPHxnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx_wPhI9HsQO",
        "outputId": "f775da0f-21ca-4918-e1a5-01fd456ef8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [Country#17 ASC NULLS FIRST, Year#22 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(Country#17 ASC NULLS FIRST, Year#22 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#673]\n",
            "      +- HashAggregate(keys=[Country#17, Year#22], functions=[avg(Avgtempcentconv#136)])\n",
            "         +- Exchange hashpartitioning(Country#17, Year#22, 200), ENSURE_REQUIREMENTS, [id=#670]\n",
            "            +- HashAggregate(keys=[Country#17, Year#22], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "               +- Project [Country#17, Year#22, (cast((cast(AvgTemperature#23 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "                  +- Filter (((isnotnull(AvgTemperature#23) AND isnotnull(region#16)) AND (cast(AvgTemperature#23 as float) > -99.0)) AND (region#16 = Asia))\n",
            "                     +- FileScan csv [Region#16,Country#17,Year#22,AvgTemperature#23] Batched: false, DataFilters: [isnotnull(AvgTemperature#23), isnotnull(Region#16), (cast(AvgTemperature#23 as float) > -99.0), ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature), IsNotNull(Region), EqualTo(Region,Asia)], ReadSchema: struct<Region:string,Country:string,Year:string,AvgTemperature:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average temperature of all countries\n",
        "df=spark.sql(\"select  AVG(Avgtempcentconv) from Temperature \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3geXbWnhtC0C",
        "outputId": "12312a12-60cc-47df-e671-b591042a96af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|avg(Avgtempcentconv)|\n",
            "+--------------------+\n",
            "|  28.541046728168215|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does Spark allows Complex SQL queries e.g. CTEs , Subqueries ?\n"
      ],
      "metadata": {
        "id": "gO5johVnHCEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get all Asian countries, year and corresponding Average temp  having their Avg temp higher than avg global temperature till now \n",
        "spark.sql(\"\"\" \\\n",
        "WITH T_avg AS ( \\\n",
        "    select avg(Avgtempcentconv) as av from Temperature \\\n",
        "), \\\n",
        "CY_AVG AS (select Country,Year, AVG(Avgtempcentconv) as atc from Temperature where region='Asia' group by 1,2) \\\n",
        "select * from CY_AVG WHERE atc >= (SELECT av from T_avg) order by atc desc\"\"\" ).explain()"
      ],
      "metadata": {
        "id": "LJw8yvzJtCxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc38805-0e1d-48a9-cf75-77eeffe25d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [atc#304 DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(atc#304 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#318]\n",
            "      +- Filter (isnotnull(atc#304) AND (atc#304 >= Subquery subquery#302, [id=#310]))\n",
            "         :  +- Subquery subquery#302, [id=#310]\n",
            "         :     +- AdaptiveSparkPlan isFinalPlan=false\n",
            "         :        +- HashAggregate(keys=[], functions=[avg(Avgtempcentconv#136)])\n",
            "         :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#308]\n",
            "         :              +- HashAggregate(keys=[], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "         :                 +- Project [(cast((cast(AvgTemperature#23 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "         :                    +- Filter (isnotnull(AvgTemperature#23) AND (cast(AvgTemperature#23 as float) > -99.0))\n",
            "         :                       +- FileScan csv [AvgTemperature#23] Batched: false, DataFilters: [isnotnull(AvgTemperature#23), (cast(AvgTemperature#23 as float) > -99.0)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature)], ReadSchema: struct<AvgTemperature:string>\n",
            "         +- HashAggregate(keys=[Country#306, Year#311], functions=[avg(Avgtempcentconv#136)])\n",
            "            +- Exchange hashpartitioning(Country#306, Year#311, 200), ENSURE_REQUIREMENTS, [id=#314]\n",
            "               +- HashAggregate(keys=[Country#306, Year#311], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "                  +- Project [Country#306, Year#311, (cast((cast(AvgTemperature#312 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "                     +- Filter (((isnotnull(AvgTemperature#312) AND isnotnull(region#305)) AND (cast(AvgTemperature#312 as float) > -99.0)) AND (region#305 = Asia))\n",
            "                        +- FileScan csv [Region#305,Country#306,Year#311,AvgTemperature#312] Batched: false, DataFilters: [isnotnull(AvgTemperature#312), isnotnull(Region#305), (cast(AvgTemperature#312 as float) > -99.0..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature), IsNotNull(Region), EqualTo(Region,Asia)], ReadSchema: struct<Region:string,Country:string,Year:string,AvgTemperature:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check the data of above query"
      ],
      "metadata": {
        "id": "PVUed27zXyVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\" \\\n",
        "WITH T_avg AS ( \\\n",
        "    select avg(Avgtempcentconv) as av from Temperature \\\n",
        "), \\\n",
        "CY_AVG AS (select Country,Year, AVG(Avgtempcentconv) as atc from Temperature where region='Asia' group by 1,2) \\\n",
        "select * from CY_AVG WHERE atc >= (SELECT av from T_avg) order by atc desc\"\"\" ).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4vQNFXjrmiB",
        "outputId": "d18c3870-7cd7-4b9d-8c91-02db99f2b0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------------------+\n",
            "|  Country|Year|               atc|\n",
            "+---------+----+------------------+\n",
            "| Thailand|1997| 42.77184178368322|\n",
            "|Indonesia|2002| 42.48148186496957|\n",
            "| Thailand|2006| 42.29984775816104|\n",
            "| Thailand|2005| 42.25281578075578|\n",
            "|Indonesia|2004|42.102481097208006|\n",
            "+---------+----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average temperature of all countries\n",
        "df=spark.sql(\"DESCRIBE Temperature \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Xtzk2SX2b7",
        "outputId": "95d87400-8aac-4507-de39-e50a30f71073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------+-------+\n",
            "|       col_name|data_type|comment|\n",
            "+---------------+---------+-------+\n",
            "|         Region|   string|   null|\n",
            "|        Country|   string|   null|\n",
            "|          State|   string|   null|\n",
            "|           City|   string|   null|\n",
            "|          Month|   string|   null|\n",
            "|            Day|   string|   null|\n",
            "|           Year|   string|   null|\n",
            "| AvgTemperature|   string|   null|\n",
            "|    Avgtempcent|    float|   null|\n",
            "|Avgtempcentconv|   double|   null|\n",
            "+---------------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets explore Spark UI .To Enable UI in Google Collab, you need to set up ngrok auth which will provide a publlic URL for you SPARK UI . To set up your token, go to https://dashboard.ngrok.com/get-started/your-authtoken"
      ],
      "metadata": {
        "id": "iKDplO3Kxql-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#findspark will allow to locate spark installation in your enviornment\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "C_qDe86akaSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import and initialize findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "iWIakdwlmGbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get your spark installation directory\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VDg8awrNJZ_P",
        "outputId": "7c0bdd5b-88cc-4ea2-b1f1-ab1cee802a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.8/dist-packages/pyspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download and install Ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#Unzip installer\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "#Setup your authtoken\n",
        "!./ngrok authtoken <Your Authtoken>\n",
        "#generate public URL\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCc1n1uQuIaO",
        "outputId": "104e66de-b559-4d9c-a359-b3f460f7c6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-04 06:01:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.237.133.81, 54.161.241.46, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  40.7MB/s    in 0.3s    \n",
            "\n",
            "2023-02-04 06:01:34 (40.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Locate public URL\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzjiQ6aWvdrl",
        "outputId": "1d0fb203-efee-49b9-8052-fa1d73f9c8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"tunnels\":[{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://ac01-34-67-227-98.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}},{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://ac01-34-67-227-98.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUqICzdbNe0O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}